https://22century.ru/popular-science-publications/ai-medical-text
Как нейросети работают с медицинскими текстами: от помощи врачам до обзорных исследований 

Машинное обучение успешно используется в медицине уже много лет. В этом материале мы расскажем, как исследователи из Philips разработали инструмент на основе нейросетей, помогающий врачам собирать статистику из электронных карт пациентов, и какие технологии они использовали.
Алгоритмы машинного обучения заметно трансформируют повседневную жизнь современного человека. Привычными стали многие технологии, которые ещё 20—30 лет назад упоминались только в книгах писателей-фантастов: мгновенный интеллектуальный поиск на тысячах и миллионах вебсайтов; развлекательные сервисы на любой вкус; рекомендательные системы, предлагающие товары и объявления с учётом наших пожеланий и предпочтений; голосовые помощники, живущие в смартфонах. 
Есть и ещё одна сфера человеческой деятельности, внедрение в которую умных алгоритмов, может быть, не столь заметно со стороны, но способно существенно повлиять на нашу жизнь. Эта область — медицина. В частности, всё активнее применяется анализ с помощью ИИ-инструментов рентгеновских и КТ-снимков, результатов микроскопии, фотоснимков высыпаний и новообразований и т.п. — и такой анализ уже может соперничать с выводами опытных диагностов-людей. Однако большая часть накопленной медицинской информации — это не снимки, а текст. Поэтому следующего прорыва в развитии медицинского искусственного интеллекта можно ожидать в области анализа естественных языков (Natural Language Processing, NLP) и его применения к медицинским данным.
Обработка естественных языков — одно из основных направлений исследований ИИ, в котором разрабатываются алгоритмы для анализа и «понимания» текстов на языках человеческого общения.
Научный сотрудник лаборатории Philips Innovation Labs Rus Федор Мушенок и приглашённый научный сотрудник Philips Research Eindhoven Вадим Ливенцев рассказали об анализе естественных языков и о своём вкладе в эту область.
Обработка естественных языков: как это работает
Для обработки текстовой информации с помощью машинного обучения необходимо перевести слова, понятные человеку, на язык компьютера. Все современные алгоритмы машинного обучения воспринимают информацию в виде векторов — последовательностей рациональных чисел. Например, предложение, состоящее из пяти слов, может быть представлено компьютеру как набор из пяти таких последовательностей. Выбор конкретного способа кодирования слов в векторы — одна из ключевых задач в обработке естественных языков, а многие значимые успехи в этой области связаны именно с изобретением новых эффективных способов кодирования. Вот самые популярные из них.
Способ 1. Присваиваем каждому слову целочисленное значение. Это, несомненно, самый очевидный метод кодирования. Он предполагает, что нужно составить словарь из всех уникальных слов определённого языка и пронумеровать их по порядку. В такой словарь может войти до десятков тысяч слов. Тогда любое слово может быть представлено вектором, количество чисел в котором равно размеру словаря. Вектор будет состоять из множества нулей и некоторого количества цифр, представляющих индекс, соответствующий номеру слова в составленном словаре. А каждое предложение будет закодировано как последовательность таких векторов.
Несмотря на кажущуюся очевидность и простоту, такой подход имеет несколько серьёзных недостатков. Во-первых, количество уникальных слов в естественном языке очень велико. Кроме того, зачастую одно и то же слово может иметь несколько форм. Например, в русском языке существительные могут склоняться, глаголы — менять окончания в зависимости от числа, рода, лица и времени. В результате словарь, или матрица слов, получается очень большим, и алгоритмам сложно его обрабатывать. Но есть и решение этой проблемы: каждое слово можно привести к начальной форме. Для имён существительных это форма единственного числа и именительного падежа; для глаголов — инфинитив и т. д. Этот процесс называется лемматизацией и позволяет значительно сократить размер словаря, а значит и упростить вычисления.
Другое препятствие — это присутствие в языках предлогов и союзов, а также некоторых часто употребляемых существительных и глаголов. Такие слова практически не несут информации о контексте и могут встречаться в тексте любой тематики. Чтобы упростить обработку текста, было предложено удалять из словаря наиболее часто встречающиеся слова. Есть и немного другой подход: рассчитать для каждого слова величину, которая называется TF-IDF (сокращение от английского «term frequency — inverse document frequency»). Этот параметр показывает «специфичность» каждого слова. Другими словами, чем больше TF-IDF, тем более точную информацию о теме текста содержит слово. Так, предлог «в» будет обладать малой TF-IDF, поскольку почти ничего не говорит о контексте. А у существительного «ракета» эта величина гораздо выше: слово сразу с высокой вероятностью указывает на космическую тематику предложения.
Ещё один недостаток такого способа кодирования заключается в невозможности оценить, насколько слова близки по смыслу. Например, слова «кружка», «чашка» и «стакан» обозначают похожие предметы и часто используются взаимозаменяемо. В то же время векторное представление, описанное выше, не учитывает, что во многих предложениях слово «кружка» можно заменить на «стакан» без существенного искажения смысла.
Способ 2. Сопоставляем слова по смыслу. Настоящая революция в области обработки естественных языков связана с идеей эмбеддингов (англ. «embedding» — вложение). Эмбеддингами слов называются их векторные представления, созданные таким образом, что близкие по смыслу слова кодируются схожими векторами. Для вычисления эмбеддингов используется гипотеза локальности: слова, которые встречаются в одинаковом окружении, имеют близкие значения. Например, эмбеддинги слов «кружка», «чашка» и «стакан» будут располагаться в одной области векторного пространства, так как они близки по смыслу.
Такой метод сохраняет и более сложные отношения между словами. Так, если в этом представлении из слова «мужчина» вычесть слово «женщина», а затем полученный вектор вычесть из слова «король», то полученный результат будет очень близок к слову «королева», то есть «король ? мужчина + женщина = королева». Другими словами, эмбеддинг содержит знание, что, если король не мужского пола, а женского, то это королева. Другой показательный пример — соотношение стран и их столиц: если из названия одной страны вычесть название её столицы, а затем результат вычесть из названия второй страны, то получим название столицы второй страны. Представление слов в виде эмбеддингов имеет целый ряд преимуществ. Помимо того, что в них сохраняется информация о смысловой близости слов, уменьшается размерность векторов, которыми кодируются слова. Это упрощает обработку текста алгоритмами.
Одна из базовых задач в обработке естественных языков заключается в обнаружении и извлечении из текстов ключевых слов и словосочетаний, которые определяют смысл всего текста. Они называются именованными сущностями. Для медицинских текстов это могут быть симптомы (например, «субфебрильная температура», «затруднённое дыхание»), названия лекарств и процедур, диагнозы (например, «ОРВИ», «артериальная гипертензия»). Извлечение из текста именованных сущностей позволяет анализировать медицинские записи и структурировать их.
Сложность задачи в том, что в большинстве текстов структура предложений не определена заранее, а одни и те же объекты или действия могут быть описаны разными словами (в частности, синонимами).
Для решения этой проблемы проводится анализ иерархической структуры предложения.
После того, как сущности извлечены и текст переведён в структурированный формат, информацию можно обработать с помощью технологий больших данных.
Но главный вызов при извлечении именованных сущностей состоит в том, что интересующие нас медицинские понятия не всегда упомянуты в утвердительном контексте. Например, в предложении «Следов эндометриоза не обнаружено» очень важно учесть, что диагноз «эндометриоз» используется в отрицании. А из предложения «Цель данного исследования — исключить или подтвердить пневмонию» нельзя сделать никаких выводов о наличии пневмонии у пациента. Таким образом встаёт задача классификации упоминаний на утвердительные, отрицательные и неопределённые. Один из подходов к решению этой задачи был предложен специалистами лаборатории Philips Research.
Какую задачу специалисты Philips решали с помощью эмбеддингов?
Philips многие знают как производителя бытовой техники, приборов для дома и ухода за собой. Однако в действительности основная специализация компании — это технологии для здравоохранения. В частности, Philips разрабатывает и производит рентгеновское оборудование, компьютерные и магнитно-резонансные томографы, а также медицинское программное обеспечение. Компания вкладывает много ресурсов в создание систем искусственного интеллекта, которые призваны помогать врачам в их непростой работе. Так, в недавнем исследовании специалисты Philips описали алгоритм на основе нейронных сетей, который позволяет обнаруживать именованные сущности и определять их контекст в медицинских текстах. С помощью этого инструмента можно получить таблицу симптомов и диагнозов пациента, упомянутых именно в утвердительном контексте. Лаборатория Philips Innovation Labs Rus, работавшая над проектом, является частью мировой сети исследовательских лабораторий Philips Research и располагается в инновационном центре «Сколково». 
Фактически программа должна была научиться отвечать на вопрос, используется ли какой-то медицинский термин в предложении, и если да, то в каком контексте (утвердительном или отрицательном). Это довольно общая задача, однако применительно к медицине она не была хорошо решена (была одна попытка, но в этом случае была слишком маленькая обучающая выборка). Приведём пример: есть предложение «Мы подозреваем, что у пациента нет определённой патологии в грудной клетке». Нейронная сеть должна классифицировать это утверждение как отрицательное упоминание патологии. Исследователям потребовалось ввести третий класс утверждений — спекулятивные, которые ничего не говорят о наличии или отсутствии заболевания, хотя его и упоминают. Например, спекулятивным будет высказывание: «Наша цель — выяснить, есть ли у пациента пневмоторакс». Выделение этого третьего класса и сделало задачу отличной от стандартной.
Нейронные сети, которые были использованы, обучаются на размеченных данных. Это значит, что для каждого предложения была указана его категория. Организовать такую разметку оказалось достаточно сложно. Нельзя было взять первого попавшегося человека на «Яндекс.Толоке», нужен был кто-то с пониманием предметной области. В итоге разметка оказалась дорогой и трудоёмкой процедурой, так что получить достаточно большой объём размеченных данных было сложно. 
«После разметки части данных медиками мы создали экспертную систему, состоящую из набора записанных правил. С её помощью можно было понять, какой тип утверждения находится в предложении. Мы применили эту систему к другой части необработанных данных. Затем мы обучили нейросеть на данных, размеченных экспертной системой, и дообучили её на данных, размеченных людьми-экспертами», — рассказывает Вадим Ливенцев, один из исследователей, работавших над проектом.
«В итоге при очень маленьком количестве размеченных вручную данных был получен результат намного лучший, чем если бы исследователи использовали только нейросеть или только экспертную систему. «Это очень модное сейчас направление — смешение экспертных знаний с ИИ», — продолжает Вадим.
Полученная исследователями модель может быть масштабирована, хоть и не со 100%-ной точностью, для применения к другим медицинским записям, помимо комментариев к КТ и МРТ, — например, к заметкам к результатам УЗИ или для работы с электронными медицинскими карточками пациентов. Но для этого придётся немного дополнить датасет, так как у врачей-радиологов довольно специфичный лексикон (они используют ряд профессиональных жаргонизмов). 
Сначала нейронная сеть обучалась на англоязычном датасете MIMIC-CXR (его можно найти в открытом доступе). Это набор рентгеновских снимков, к которым прилагаются текстовые описания, написанные врачами. При локализации модели (переводе на русский) были использованы тексты, написанные врачами за годы. Philips сотрудничает с большим количеством больниц, и некоторые из них оказались готовы предоставить данные. При этом данные должны были быть собраны этично и использованы только с согласия пациентов, которые должны были подписать договор информированного согласия. Кроме того, перед работой с данными их анонимизировали — удаляли явно прописанные имена и любую информацию, которая может помочь однозначно идентифицировать пациента (например, время, когда был сделан снимок, в какой больнице проводилась процедура).
Где такой инструмент можно применить? Если врач захочет узнать какую-то статистику по своей больнице, например, в каком проценте случаев определённая болезнь даёт осложнение, он может сформировать запрос системе. Она создаст базу данных — извлечёт информацию из текстов — и далее с помощью других инструментов можно будет получить сводную таблицу историй болезни со всеми требуемыми параметрами. С помощью этого подхода по каждому вопросу можно узнать подробности, например, каков средний людей, у которых конкретная болезнь даёт осложнения, в каком количестве случаев патология встречается у молодых или у пожилых пациентов. Более сложные системы, которые можно реализовать, имея на руках данные в табличной форме, — это предиктивные, способные на основе данных давать свою оценку сценария. Например, что скорее всего будет происходить с тем или иным пациентом, если с ним ничего не сделать, или если произвести ту или иную интервенцию.
Другая область применения такого инструмента — медицинские исследования. Во всём мире ежегодно проводится огромное их количество. Некоторые из них направлены на разработку новых лекарств, другие — на исследование причин болезней и поиск оптимальных методов лечения, и т.д. Результат большинства работ — статьи и отчёты, опубликованные в научных журналах. При этом исследования могут противоречить друг другу из-за ошибок в планировании экспериментов, разных методик обработки результатов, предвзятости исследователей и влияния других неучтённых факторов. Так, множество учёных изучало влияние кофе на организм человека и его здоровье. В итоге часть исследований показала, что кофе вреден для сердца и желудка, а в других утверждается, что он способен защитить организм от диабета и рака. Чтобы составить целостную картину на основе большого количества противоречивых сведений, нужно найти и прочитать все имеющиеся исследования, выявить основные факты и возможные недостатки этих исследований, а зачем обобщить их результаты. Такая задача может стать непосильной для одного человека или даже для исследовательского коллектива: количество публикаций огромно, а новые выходят практически каждый день. И здесь на помощь снова приходят алгоритмы обработки естественных языков. С помощью полученного инструмента можно из огромного объёма исследований извлечь все именованные сущности, соответствующие болезням, и затем исследовать выборку пациентов с определённым состоянием, например, гипертонией. И далее можно исследовать, как течения болезни разных пациентов соотносятся между собой, при каких сопутствующих условиях болезнь протекает тяжелее. 
Искусственный интеллект в медицине помогает врачам, но положительный эффект почувствуют на себе не только они, но и каждый из пациентов. В конечном счёте все подобные разработки направлены на одно — улучшение качества медицинской помощи. Именно поэтому обработке естественных языков в медицине сейчас уделяется так много внимания. Безусловно, усилия разработчиков принесут плоды в ближайшем будущем.

